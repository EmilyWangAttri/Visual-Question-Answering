prefix: vqa_base
model_name: vqa_base
mode: 'train'
save_dir: '/home/cse/phd/csz178057/project/outputs'

"""
use_gpu
data_dir
save_dir
rnn_class
reload
test
batch_size
epochs
lr
step_size
gamma
seed


"""
data:
    #which_data supports two values: 'Cifar10' and ImagenetMini
    which_data: imagenetmini
    path: '/home/cse/phd/csz178057/phd/dl/data/TestImageNet'
    seed: 0
    shuffle: True
    augment_test: False
    deep_dir: False
    loader_params:
        batch_size: 128
        num_workers: 2
        pin_memory: True

checkpoints:
    path: 'checkpoints.pth.tar'
    best_model_path: 'best_model_checkpoint.pth.tar'

stats:
    trainTimeLogs: 'trainingTime.csv'
    accuracyLogs: 'accuracyLogs.csv'

optim:
    class: sgd
    #decay_factor: 0.1
    #how_many_epochs: 2000
    scheduler: 'CustomReduceLROnPlateau'
    
    scheduler_params:
        maxPatienceToStopTraining: 15
        base_class_params:
            mode: 'min'
            factor: 0.1
            patience: 10
            verbose: True 
            threshold: 0.05 
            threshold_mode: 'rel' 
            cooldown: 0 
            min_lr: 0.0001
            eps: 0.000001

    params: 
        momentum: 0.9
        lr: 0.01
        weight_decay: 0.0005 
        #betas: [0.9,0.999]
        #eps: 1e-08

training:
    no_of_epochs: 100
    start_from_checkpoint: True
    max_noof_lr_updates: 4

model:
    arch:
        conv_layers:
            #layer1
            -   conv:
                    in_channels: 3
                    out_channels: 96
                    kernel_size: 11
                    stride: 4
                    padding: 0

                non_linearity: 
                    type: ReLU
                    params:
                        inplace: True
                       
                                    
                pool:
                    kernel_size: 3  
                    stride: 2
                   
            #layer2 
            -   conv:
                    in_channels: 96
                    out_channels: 256
                    kernel_size: 5
                    stride: 1
                    padding: 2
                
                non_linearity:
                    type: ReLU
                    params:
                        inplace: True
    
                pool:
                    kernel_size: 3
                    stride: 2
    
            #layer3 
            -   conv:
                    in_channels: 256
                    out_channels: 384
                    kernel_size: 3
                    stride: 1
                    padding: 1
                
                non_linearity: 
                    type: ReLU
                    params:
                        inplace: True
    
            #layer4
            -   conv:
                    in_channels: 384
                    out_channels: 384
                    kernel_size: 3
                    stride: 1
                    padding: 1
                
                non_linearity: 
                    type: ReLU
                    params:
                        inplace: True
    
            #layer5
            -   conv:
                    in_channels: 384
                    out_channels: 256
                    kernel_size: 3
                    stride: 1
                    padding: 1
                
                non_linearity:
                    type: ReLU
                    params:
                        inplace: True
    
                pool:
                    kernel_size: 3
                    stride: 2

        fc_layers:
            #fclayer1
            -   linear:
                    #9216 = 5*5*256
                    in_features: 9216
                    out_features: 4096
                    bias: True

                non_linearity:
                    type: ReLU
                    params:
                        inplace: True
                
                dropout:
                    p: 0.5
                    inplace: False
   
            #fclayer2 
            -   linear:
                    in_features: 4096
                    out_features: 4096
                    bias: True

                non_linearity: 
                    type: ReLU
                    params:
                        inplace: True
           
                dropout:
                    p: 0.5
                    inplace: False

            #fclayer3 
            -   linear:
                    in_features: 4096
                    out_features: 35
                    bias: True


#after conv1 55
#after pool1 27
#after conv2 23
#after pool2 11
#pad with 2 for conv3
#after conv3 11
#pad with 2 for conv4
#after conv4 11
#pad with 2 for conv5
#after conv5 11
#after pool5 5
